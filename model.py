from vit_pytorch.max_vit import MaxViT


class MaxVit_Model:
    def __init__(self, model_config, device) -> None:
        self.model_config = model_config
        self.device = device
    def model(self):
        cf = self.model_config
        return MaxViT(
            num_classes = cf['num_classes'],
            dim_conv_stem = cf['dim_conv_stem'],          # dimension of the convolutional stem, would default to dimension of first layer if not specified
            dim = cf['dim'],                              # dimension of first layer, doubles every layer
            dim_head = cf['dim_head'],                    # dimension of attention heads, kept at 32 in paper
            depth = tuple(cf['depth']),                   # number of MaxViT blocks per stage, which consists of MBConv, block-like attention, grid-like attention
            window_size = cf['window_size'],                        # window size for block and grids
            mbconv_expansion_rate = cf['mbconv_expansion_rate'],    # expansion rate of MBConv
            mbconv_shrinkage_rate = cf['mbconv_shrinkage_rate'],    # shrinkage rate of squeeze-excitation in MBConv
            dropout = cf['mbconv_shrinkage_rate']                   # dropout
        ).to(self.device)